{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMB5zWQ4ZQdyZYZCbcyxvSC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishal172-blip/Certificates_Link/blob/main/Assigement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFy67EPDb8Ny",
        "outputId": "2df1ac5d-c2b8-4063-b064-2a56d4b6f363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. User: Hi there!\n",
            "2. Assistant: Hello! How can I help you?\n",
            "3. User: Can you tell me about Groq APIs?\n",
            "4. Assistant: Sure! Groq provides OpenAI-compatible APIs for AI/ML tasks.\n",
            "\n",
            "Total conversation runs so far: 2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Conversation history will be stored here as a list of dictionaries\n",
        "conversation_history = []\n",
        "\n",
        "# Counter to keep track of how many user-assistant exchanges (runs) have occurred\n",
        "run_count = 0\n",
        "\n",
        "def add_message(role: str, content: str):\n",
        "    \"\"\"\n",
        "    Add a message to the conversation history.\n",
        "    role: 'user' or 'assistant'\n",
        "    content: message text\n",
        "    \"\"\"\n",
        "    global run_count\n",
        "    if role == \"assistant\":\n",
        "        # Increment run count each time assistant responds (marks a full exchange)\n",
        "        run_count += 1\n",
        "\n",
        "    message = {\n",
        "        \"role\": role,\n",
        "        \"content\": content\n",
        "    }\n",
        "    conversation_history.append(message)\n",
        "\n",
        "def get_history():\n",
        "    \"\"\"Return the full conversation history as a list of messages.\"\"\"\n",
        "    return conversation_history\n",
        "\n",
        "# ---- Demo: Adding some sample messages ----\n",
        "\n",
        "add_message(\"user\", \"Hi there!\")\n",
        "add_message(\"assistant\", \"Hello! How can I help you?\")\n",
        "add_message(\"user\", \"Can you tell me about Groq APIs?\")\n",
        "add_message(\"assistant\", \"Sure! Groq provides OpenAI-compatible APIs for AI/ML tasks.\")\n",
        "\n",
        "# Print the current conversation history\n",
        "for idx, msg in enumerate(get_history(), start=1):\n",
        "    print(f\"{idx}. {msg['role'].capitalize()}: {msg['content']}\")\n",
        "\n",
        "# Print run count to show how many assistant replies so far\n",
        "print(\"\\nTotal conversation runs so far:\", run_count)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Reuse the conversation_history and run_count from Part 1\n",
        "# Assuming you already ran Part 1 code in the same notebook.\n",
        "\n",
        "def truncate_history_by_turns(n: int):\n",
        "    \"\"\"\n",
        "    Return the last n messages from the conversation history.\n",
        "    Does not modify the original history.\n",
        "    \"\"\"\n",
        "    return conversation_history[-n:] if n < len(conversation_history) else conversation_history.copy()\n",
        "\n",
        "def truncate_history_by_length(max_chars: int):\n",
        "    \"\"\"\n",
        "    Return a truncated copy of the conversation history\n",
        "    limited by total character length.\n",
        "    Iterates from newest to oldest and stops when limit is reached.\n",
        "    \"\"\"\n",
        "    truncated = []\n",
        "    total_chars = 0\n",
        "    # Iterate in reverse (newest first)\n",
        "    for msg in reversed(conversation_history):\n",
        "        length = len(msg['content'])\n",
        "        if total_chars + length > max_chars:\n",
        "            break\n",
        "        truncated.insert(0, msg)  # insert at start to maintain order\n",
        "        total_chars += length\n",
        "    return truncated\n",
        "\n",
        "# ---- Demo: Show truncation ----\n",
        "\n",
        "print(\"=== Full History ===\")\n",
        "for i, m in enumerate(conversation_history, 1):\n",
        "    print(f\"{i}. {m['role'].capitalize()}: {m['content']}\")\n",
        "\n",
        "# Truncate by last 3 messages\n",
        "print(\"\\n=== Truncate: Last 3 Messages ===\")\n",
        "for i, m in enumerate(truncate_history_by_turns(3), 1):\n",
        "    print(f\"{i}. {m['role'].capitalize()}: {m['content']}\")\n",
        "\n",
        "# Truncate by max 50 characters\n",
        "print(\"\\n=== Truncate: Max 50 Characters ===\")\n",
        "for i, m in enumerate(truncate_history_by_length(50), 1):\n",
        "    print(f\"{i}. {m['role'].capitalize()}: {m['content']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8PDuMU6cAoi",
        "outputId": "4217ed6f-9655-427b-d197-4fc334e34221"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Full History ===\n",
            "1. User: Hi there!\n",
            "2. Assistant: Hello! How can I help you?\n",
            "3. User: Can you tell me about Groq APIs?\n",
            "4. Assistant: Sure! Groq provides OpenAI-compatible APIs for AI/ML tasks.\n",
            "\n",
            "=== Truncate: Last 3 Messages ===\n",
            "1. Assistant: Hello! How can I help you?\n",
            "2. User: Can you tell me about Groq APIs?\n",
            "3. Assistant: Sure! Groq provides OpenAI-compatible APIs for AI/ML tasks.\n",
            "\n",
            "=== Truncate: Max 50 Characters ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "conversation_data = [\n",
        "    {\"user_message\": \"Hi\", \"assistant_response\": \"Hello!\"},\n",
        "    {\"user_message\": \"What's the price?\", \"assistant_response\": \"It's $10.\"},\n",
        "    {\"user_message\": \"Thanks!\", \"assistant_response\": \"You're welcome!\"}\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(conversation_data)\n",
        "df.to_csv(\"conversation_logs.csv\", index=False)\n",
        "print(\"conversation_logs.csv saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFl3K7bkcLaE",
        "outputId": "e3121686-cb95-492b-b3a4-55c493001358"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conversation_logs.csv saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Process and analyze the stored conversational data.\n",
        "\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Load the stored conversation logs\n",
        "df = pd.read_csv(\"conversation_logs.csv\")\n",
        "\n",
        "# --- Basic cleaning ---\n",
        "# Strip whitespace and drop any completely empty messages\n",
        "df['user_message'] = df['user_message'].str.strip()\n",
        "df['assistant_response'] = df['assistant_response'].str.strip()\n",
        "df.dropna(subset=['user_message', 'assistant_response'], inplace=True)\n",
        "\n",
        "# --- Basic statistics ---\n",
        "# Count total conversations\n",
        "total_conversations = df.shape[0]\n",
        "\n",
        "# Count average message length for user and assistant\n",
        "avg_user_len = df['user_message'].apply(len).mean()\n",
        "avg_assistant_len = df['assistant_response'].apply(len).mean()\n",
        "\n",
        "# Identify most common words in user messages\n",
        "all_words = \" \".join(df['user_message']).lower().split()\n",
        "common_words = Counter(all_words).most_common(10)\n",
        "\n",
        "# --- Filter conversations by keyword (example) ---\n",
        "def filter_by_keyword(keyword):\n",
        "    return df[df['user_message'].str.contains(keyword, case=False)]\n",
        "\n",
        "# --- Print summary ---\n",
        "print(f\"Total conversations stored: {total_conversations}\")\n",
        "print(f\"Average user message length: {avg_user_len:.2f} characters\")\n",
        "print(f\"Average assistant response length: {avg_assistant_len:.2f} characters\\n\")\n",
        "\n",
        "print(\"Top 10 most common words in user messages:\")\n",
        "for word, count in common_words:\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# Example filter usage:\n",
        "print(\"\\nSample conversations mentioning 'price':\")\n",
        "print(filter_by_keyword('price').head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLFfMQPfcT9_",
        "outputId": "911c1b07-9d89-416e-9767-f928db638f59"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total conversations stored: 3\n",
            "Average user message length: 8.67 characters\n",
            "Average assistant response length: 10.00 characters\n",
            "\n",
            "Top 10 most common words in user messages:\n",
            "hi: 1\n",
            "what's: 1\n",
            "the: 1\n",
            "price?: 1\n",
            "thanks!: 1\n",
            "\n",
            "Sample conversations mentioning 'price':\n",
            "        user_message assistant_response\n",
            "1  What's the price?          It's $10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# ---------- Load & Analyze Data ----------\n",
        "df = pd.read_csv(\"conversation_logs.csv\")\n",
        "df['user_message'] = df['user_message'].str.strip()\n",
        "df['assistant_response'] = df['assistant_response'].str.strip()\n",
        "df.dropna(subset=['user_message','assistant_response'], inplace=True)\n",
        "\n",
        "total_conversations = df.shape[0]\n",
        "avg_user_len = df['user_message'].apply(len).mean()\n",
        "avg_assistant_len = df['assistant_response'].apply(len).mean()\n",
        "all_words = \" \".join(df['user_message']).lower().split()\n",
        "common_words = Counter(all_words).most_common(10)\n",
        "\n",
        "# ---------- Truncate History ----------\n",
        "def truncate_history_by_turns(history, n):\n",
        "    return history[-n:]\n",
        "\n",
        "conversation_history = list(\n",
        "    df[['user_message','assistant_response']].itertuples(index=False, name=None)\n",
        ")\n",
        "truncated = truncate_history_by_turns(conversation_history, 5)\n",
        "\n",
        "# ---------- Fake Summarization ----------\n",
        "history_text = \"\\n\".join([f\"User: {u}\\nAssistant: {a}\" for u,a in truncated])\n",
        "summary = \"• User mostly asks about prices.\\n• Assistant gives concise answers.\\n• Conversation is polite and short.\\n• Most common topic is product info.\"\n",
        "\n",
        "# ---------- Final Report ----------\n",
        "print(\"=== 📊 Stats Report ===\")\n",
        "print(f\"Total conversations stored: {total_conversations}\")\n",
        "print(f\"Average user message length: {avg_user_len:.2f} characters\")\n",
        "print(f\"Average assistant response length: {avg_assistant_len:.2f} characters\\n\")\n",
        "\n",
        "print(\"Top 10 most common words in user messages:\")\n",
        "for word,count in common_words:\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "print(\"\\n=== 📝 Simulated Summary of Recent History ===\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiwyVpsqdXxW",
        "outputId": "aed62567-87b7-468d-eb5c-d35d855b51ba"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 📊 Stats Report ===\n",
            "Total conversations stored: 3\n",
            "Average user message length: 8.67 characters\n",
            "Average assistant response length: 10.00 characters\n",
            "\n",
            "Top 10 most common words in user messages:\n",
            "hi: 1\n",
            "what's: 1\n",
            "the: 1\n",
            "price?: 1\n",
            "thanks!: 1\n",
            "\n",
            "=== 📝 Simulated Summary of Recent History ===\n",
            "• User mostly asks about prices.\n",
            "• Assistant gives concise answers.\n",
            "• Conversation is polite and short.\n",
            "• Most common topic is product info.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pkr6UMhwf_v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2"
      ],
      "metadata": {
        "id": "41cZftg3gOSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# JSON Schema Creation for extracting 5 details from chat\n",
        "\n",
        "import json\n",
        "\n",
        "# Define the JSON schema\n",
        "chat_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\", \"description\": \"Name of the user\"},\n",
        "        \"email\": {\"type\": \"string\", \"format\": \"email\", \"description\": \"Email of the user\"},\n",
        "        \"phone\": {\"type\": \"string\", \"description\": \"Phone number of the user\"},\n",
        "        \"location\": {\"type\": \"string\", \"description\": \"Location of the user\"},\n",
        "        \"age\": {\"type\": \"integer\", \"description\": \"Age of the user\"}\n",
        "    },\n",
        "    \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"]\n",
        "}\n",
        "\n",
        "# Print schema nicely\n",
        "print(json.dumps(chat_schema, indent=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87_IQuYEgQf2",
        "outputId": "ea7a524d-d625-4bb3-be12-74cc030bbe63"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"type\": \"object\",\n",
            "    \"properties\": {\n",
            "        \"name\": {\n",
            "            \"type\": \"string\",\n",
            "            \"description\": \"Name of the user\"\n",
            "        },\n",
            "        \"email\": {\n",
            "            \"type\": \"string\",\n",
            "            \"format\": \"email\",\n",
            "            \"description\": \"Email of the user\"\n",
            "        },\n",
            "        \"phone\": {\n",
            "            \"type\": \"string\",\n",
            "            \"description\": \"Phone number of the user\"\n",
            "        },\n",
            "        \"location\": {\n",
            "            \"type\": \"string\",\n",
            "            \"description\": \"Location of the user\"\n",
            "        },\n",
            "        \"age\": {\n",
            "            \"type\": \"integer\",\n",
            "            \"description\": \"Age of the user\"\n",
            "        }\n",
            "    },\n",
            "    \"required\": [\n",
            "        \"name\",\n",
            "        \"email\",\n",
            "        \"phone\",\n",
            "        \"location\",\n",
            "        \"age\"\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sample chat parsing using the JSON schema (simulated without real API)\n",
        "\n",
        "import json\n",
        "\n",
        "# Sample chats\n",
        "sample_chats = [\n",
        "    \"Hi, my name is Vishal Kumar. My email is vishal@example.com, phone 9876543210, I live in Delhi and I am 20 years old.\",\n",
        "    \"Hello, I'm Priya Sharma, email priya123@mail.com, phone 9123456789, from Mumbai, 22 years old.\",\n",
        "    \"Hey, name is Raj, email raj456@gmail.com, phone 9988776655, living in Bangalore, age 25.\"\n",
        "]\n",
        "\n",
        "# Function to simulate extraction using the schema\n",
        "def extract_info_from_chat(chat_text):\n",
        "    # This is a simulated parser; in real scenario Groq/OpenAI function would do this\n",
        "    info = {\n",
        "        \"name\": \"\",\n",
        "        \"email\": \"\",\n",
        "        \"phone\": \"\",\n",
        "        \"location\": \"\",\n",
        "        \"age\": 0\n",
        "    }\n",
        "    # Simple extraction using splits (basic simulation)\n",
        "    import re\n",
        "    name_match = re.search(r\"name is (\\w+ \\w+)|I'm (\\w+ \\w+)|name is (\\w+)\", chat_text)\n",
        "    info['name'] = next((m for m in name_match.groups() if m), \"\")\n",
        "\n",
        "    email_match = re.search(r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", chat_text)\n",
        "    info['email'] = email_match.group() if email_match else \"\"\n",
        "\n",
        "    phone_match = re.search(r\"\\b\\d{10}\\b\", chat_text)\n",
        "    info['phone'] = phone_match.group() if phone_match else \"\"\n",
        "\n",
        "    loc_match = re.search(r\"live in (\\w+)|from (\\w+)|living in (\\w+)\", chat_text)\n",
        "    info['location'] = next((m for m in loc_match.groups() if m), \"\")\n",
        "\n",
        "    age_match = re.search(r\"(\\d{2}) years old|age (\\d{2})\", chat_text)\n",
        "    info['age'] = int(next((m for m in age_match.groups() if m), 0))\n",
        "\n",
        "    return info\n",
        "\n",
        "# Parse all sample chats\n",
        "parsed_outputs = [extract_info_from_chat(chat) for chat in sample_chats]\n",
        "\n",
        "# Print JSON outputs\n",
        "for i, output in enumerate(parsed_outputs, 1):\n",
        "    print(f\"--- Chat {i} Parsed ---\")\n",
        "    print(json.dumps(output, indent=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4LHAKb0gY7J",
        "outputId": "8bf4c8c6-f849-41b1-d32b-c628b2261938"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chat 1 Parsed ---\n",
            "{\n",
            "    \"name\": \"Vishal Kumar\",\n",
            "    \"email\": \"vishal@example.com\",\n",
            "    \"phone\": \"9876543210\",\n",
            "    \"location\": \"Delhi\",\n",
            "    \"age\": 20\n",
            "}\n",
            "--- Chat 2 Parsed ---\n",
            "{\n",
            "    \"name\": \"Priya Sharma\",\n",
            "    \"email\": \"priya123@mail.com\",\n",
            "    \"phone\": \"9123456789\",\n",
            "    \"location\": \"Mumbai\",\n",
            "    \"age\": 22\n",
            "}\n",
            "--- Chat 3 Parsed ---\n",
            "{\n",
            "    \"name\": \"Raj\",\n",
            "    \"email\": \"raj456@gmail.com\",\n",
            "    \"phone\": \"9988776655\",\n",
            "    \"location\": \"Bangalore\",\n",
            "    \"age\": 25\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Task 2: Part 3 ---\n",
        "# Validate parsed JSON outputs against schema\n",
        "\n",
        "from jsonschema import validate, ValidationError\n",
        "\n",
        "# Reuse the schema from Part 1\n",
        "chat_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\", \"description\": \"Name of the user\"},\n",
        "        \"email\": {\"type\": \"string\", \"format\": \"email\", \"description\": \"Email of the user\"},\n",
        "        \"phone\": {\"type\": \"string\", \"description\": \"Phone number of the user\"},\n",
        "        \"location\": {\"type\": \"string\", \"description\": \"Location of the user\"},\n",
        "        \"age\": {\"type\": \"integer\", \"description\": \"Age of the user\"}\n",
        "    },\n",
        "    \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"]\n",
        "}\n",
        "\n",
        "# Assume parsed_outputs from Part 2\n",
        "# parsed_outputs = [...]\n",
        "\n",
        "# Validate each JSON\n",
        "for i, output in enumerate(parsed_outputs, 1):\n",
        "    try:\n",
        "        validate(instance=output, schema=chat_schema)\n",
        "        print(f\"Chat {i}: ✅ Valid\")\n",
        "    except ValidationError as e:\n",
        "        print(f\"Chat {i}: ❌ Invalid - {e.message}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hR3LeHugiJP",
        "outputId": "5b2ef271-5e76-4e6f-de6f-aed5638f018b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat 1: ✅ Valid\n",
            "Chat 2: ✅ Valid\n",
            "Chat 3: ✅ Valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from jsonschema import validate, ValidationError\n",
        "\n",
        "# ---------- Groq API Key ----------\n",
        "api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"GROQ_API_KEY not found. Set it with `%env GROQ_API_KEY=your_key`\")\n",
        "\n",
        "client = OpenAI(base_url=\"https://api.groq.com/openai/v1\", api_key=api_key)\n",
        "\n",
        "# ---------- JSON Schema ----------\n",
        "chat_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\"},\n",
        "        \"email\": {\"type\": \"string\", \"format\": \"email\"},\n",
        "        \"phone\": {\"type\": \"string\"},\n",
        "        \"location\": {\"type\": \"string\"},\n",
        "        \"age\": {\"type\": \"integer\"}\n",
        "    },\n",
        "    \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"]\n",
        "}\n",
        "\n",
        "# ---------- Sample Chats ----------\n",
        "sample_chats = [\n",
        "    \"Hi, my name is Vishal Kumar. My email is vishal@example.com, phone 9876543210, I live in Delhi and I am 20 years old.\",\n",
        "    \"Hello, I'm Priya Sharma, email priya123@mail.com, phone 9123456789, from Mumbai, 22 years old.\",\n",
        "    \"Hey, name is Raj, email raj456@gmail.com, phone 9988776655, living in Bangalore, age 25.\"\n",
        "]\n",
        "\n",
        "# ---------- Function to Extract Info Using Groq ----------\n",
        "def extract_info_groq(chat_text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"groq/compound-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"Extract the following info in JSON format exactly matching this schema: \"\n",
        "                    + json.dumps(chat_schema)\n",
        "                )\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": chat_text}\n",
        "        ],\n",
        "        max_tokens=200\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Parse API response to JSON\n",
        "        result_text = response.choices[0].message.content.strip()\n",
        "        result_json = json.loads(result_text)\n",
        "\n",
        "        # Validate against schema\n",
        "        validate(instance=result_json, schema=chat_schema)\n",
        "        return result_json\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        # Agar JSON parse fail ho jaye\n",
        "        return {\"error\": \"Invalid JSON returned\", \"raw_output\": response.choices[0].message.content}\n",
        "\n",
        "    except ValidationError as ve:\n",
        "        # Agar schema validate fail ho jaye\n",
        "        return {\"error\": f\"Schema validation failed: {ve.message}\", \"raw_output\": result_text}\n",
        "\n",
        "# ---------- Process All Sample Chats ----------\n",
        "parsed_outputs = [extract_info_groq(chat) for chat in sample_chats]\n",
        "\n",
        "# ---------- Print Final Structured Outputs ----------\n",
        "for i, output in enumerate(parsed_outputs, 1):\n",
        "    print(f\"--- Chat {i} Parsed ---\")\n",
        "    print(json.dumps(output, indent=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_Xb2SVTgpTF",
        "outputId": "217769ee-01ad-4a69-efec-ce1c91caa5b5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chat 1 Parsed ---\n",
            "{\n",
            "    \"error\": \"Invalid JSON returned\",\n",
            "    \"raw_output\": \"Based on the information you provided, here is the extracted data in JSON format:\\n\\n```\\n{\\n  \\\"name\\\": \\\"Vishal Kumar\\\",\\n  \\\"email\\\": \\\"vishal@example.com\\\",\\n  \\\"phone\\\": \\\"9876543210\\\",\\n  \\\"location\\\": \\\"Delhi\\\",\\n  \\\"age\\\": 20\\n}\\n```\"\n",
            "}\n",
            "--- Chat 2 Parsed ---\n",
            "{\n",
            "    \"error\": \"Invalid JSON returned\",\n",
            "    \"raw_output\": \"Based on the information you provided, here is the extracted data in JSON format:\\n\\n```\\n{\\n  \\\"name\\\": \\\"Priya Sharma\\\",\\n  \\\"email\\\": \\\"priya123@mail.com\\\",\\n  \\\"phone\\\": \\\"9123456789\\\",\\n  \\\"location\\\": \\\"Mumbai\\\",\\n  \\\"age\\\": 22\\n}\\n```\"\n",
            "}\n",
            "--- Chat 3 Parsed ---\n",
            "{\n",
            "    \"error\": \"Invalid JSON returned\",\n",
            "    \"raw_output\": \"Based on the information provided, here is the extracted data in JSON format:\\n\\n```\\n{\\n  \\\"name\\\": \\\"Raj\\\",\\n  \\\"email\\\": \\\"raj456@gmail.com\\\",\\n  \\\"phone\\\": \\\"9988776655\\\",\\n  \\\"location\\\": \\\"Bangalore\\\",\\n  \\\"age\\\": 25\\n}\\n```\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cWdytmsuh3BF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}